# Guide: Pr√©-entra√Æner et Exporter le Mod√®le AI

## Pourquoi Pr√©-entra√Æner ?

Actuellement, le mod√®le s'entra√Æne au **premier lancement** de l'app (30 epochs = ~10-15 secondes).

Pour une exp√©rience optimale, vous pouvez :
1. **Pr√©-entra√Æner le mod√®le** sur votre machine de dev
2. **L'exporter** dans les assets de l'app
3. **Le charger** au lieu de l'entra√Æner

## Option 1: Entra√Ænement Automatique (Actuel) ‚úÖ

### Comment √ßa fonctionne maintenant

1. **Premier lancement** : Le mod√®le s'entra√Æne (30 epochs, ~10s)
   ```
   LOG  üèãÔ∏è Training model...
   LOG  Epoch 0: loss = 2.88, accuracy = 0.09
   LOG  Epoch 10: loss = 2.36, accuracy = 0.28
   LOG  Epoch 20: loss = 1.65, accuracy = 0.57
   LOG  Epoch 29: loss = 0.52, accuracy = 0.95
   LOG  ‚úÖ Training complete! Final accuracy: 95%
   LOG  üíæ Model and weights saved successfully
   ```

2. **Lancements suivants** : Le mod√®le se charge depuis AsyncStorage (~1s)
   ```
   LOG  ‚úÖ Model loaded from storage
   LOG  ‚úÖ Intent Classifier initialized successfully
   ```

### Avantages
- ‚úÖ Aucune configuration n√©cessaire
- ‚úÖ Le mod√®le s'adapte automatiquement si vous modifiez TRAINING_DATA
- ‚úÖ Sauvegarde persistante apr√®s le premier entra√Ænement

### Inconv√©nients
- ‚ö†Ô∏è ~10 secondes au premier lancement
- ‚ö†Ô∏è N√©cessite de r√©-entra√Æner si l'utilisateur supprime les donn√©es de l'app

---

## Option 2: Mod√®le Pr√©-entra√Æn√© (Avanc√©) üöÄ

### √âtape 1: Cr√©er un Script d'Entra√Ænement Node.js

Cr√©ez `mobile/scripts/trainModel.js` :

```javascript
const tf = require('@tensorflow/tfjs-node');
const fs = require('fs');
const path = require('path');

// Import training data
const { TRAINING_DATA, INTENT_LABELS } = require('../src/services/aiEngine/trainingData');
const { vocabularyBuilder } = require('../src/services/aiEngine/vocabularyBuilder');

async function trainAndExportModel() {
  console.log('üèóÔ∏è Creating model...');

  // Build vocabulary
  const vocabulary = vocabularyBuilder.build();
  const vocabularySize = 500;

  // Create model (same architecture as intentClassifier.ts)
  const model = tf.sequential();

  model.add(tf.layers.dense({
    inputShape: [vocabularySize],
    units: 128,
    activation: 'relu',
    kernelInitializer: 'heNormal'
  }));

  model.add(tf.layers.dropout({ rate: 0.3 }));

  model.add(tf.layers.dense({
    units: 64,
    activation: 'relu',
    kernelInitializer: 'heNormal'
  }));

  model.add(tf.layers.dropout({ rate: 0.2 }));

  model.add(tf.layers.dense({
    units: INTENT_LABELS.length,
    activation: 'softmax'
  }));

  model.compile({
    optimizer: tf.train.adam(0.001),
    loss: 'categoricalCrossentropy',
    metrics: ['accuracy']
  });

  console.log('üèãÔ∏è Training model...');

  // Prepare training data (implement textToVector logic)
  const { inputs, labels } = prepareTrainingData(TRAINING_DATA, vocabulary, vocabularySize);

  // Train
  const history = await model.fit(inputs, labels, {
    epochs: 50,  // More epochs for pre-training
    batchSize: 16,
    validationSplit: 0.2,
    shuffle: true,
    callbacks: {
      onEpochEnd: (epoch, logs) => {
        console.log(`Epoch ${epoch}: loss = ${logs.loss.toFixed(4)}, accuracy = ${logs.acc.toFixed(4)}`);
      }
    }
  });

  console.log('üíæ Saving model...');

  // Save model to file
  const modelPath = path.join(__dirname, '../assets/pretrained-model');
  await model.save(`file://${modelPath}`);

  // Save vocabulary and metadata
  const metadata = {
    vocabularySize,
    intentLabels: INTENT_LABELS,
    trainedAt: new Date().toISOString(),
    finalAccuracy: history.history.acc[history.history.acc.length - 1]
  };

  fs.writeFileSync(
    path.join(__dirname, '../assets/pretrained-model/metadata.json'),
    JSON.stringify(metadata, null, 2)
  );

  // Save vocabulary
  fs.writeFileSync(
    path.join(__dirname, '../assets/pretrained-model/vocabulary.json'),
    JSON.stringify(Array.from(vocabulary.entries()), null, 2)
  );

  console.log('‚úÖ Model exported successfully!');
  console.log(`   Path: ${modelPath}`);
  console.log(`   Final accuracy: ${(metadata.finalAccuracy * 100).toFixed(2)}%`);
}

// Helper function (implement same logic as intentClassifier.ts)
function prepareTrainingData(examples, vocabulary, vocabularySize) {
  // ... (implement textToVector logic)
}

trainAndExportModel().catch(console.error);
```

### √âtape 2: Ex√©cuter l'Entra√Ænement

```bash
cd mobile
npm install @tensorflow/tfjs-node
node scripts/trainModel.js
```

### √âtape 3: Modifier `intentClassifier.ts` pour Charger le Mod√®le Pr√©-entra√Æn√©

```typescript
private async loadModel(): Promise<boolean> {
  try {
    // Try loading from AsyncStorage first (user-trained model)
    const metadata = await AsyncStorage.getItem(MODEL_METADATA_KEY);
    if (metadata) {
      this.model = await tf.loadLayersModel(asyncStorageIO('intent_classifier'));
      console.log('‚úÖ Model loaded from AsyncStorage');
      return true;
    }

    // Fallback: Load pre-trained model from assets
    const pretrainedPath = 'file://./assets/pretrained-model/model.json';
    this.model = await tf.loadLayersModel(pretrainedPath);
    console.log('‚úÖ Pre-trained model loaded from assets');
    return true;
  } catch (error) {
    console.log('üìö Could not load model:', error.message);
    return false;
  }
}
```

### Avantages
- ‚úÖ **D√©marrage instantan√©** (~1s au lieu de ~10s)
- ‚úÖ Fonctionne m√™me sans connexion internet
- ‚úÖ Mod√®le optimis√© avec plus d'epochs (50 au lieu de 30)

### Inconv√©nients
- ‚ö†Ô∏è N√©cessite de r√©-exporter si vous modifiez TRAINING_DATA
- ‚ö†Ô∏è Augmente la taille de l'app (~200KB pour le mod√®le)

---

## Option 3: Mod√®le Distant (Future Enhancement)

Pour une vraie app en production, vous pourriez :

1. **H√©berger le mod√®le** sur un CDN (Firebase Storage, S3, etc.)
2. **Le t√©l√©charger** au premier lancement
3. **Le mettre en cache** localement

Avantages :
- ‚úÖ Taille d'app minimale
- ‚úÖ Mises √† jour du mod√®le sans release d'app
- ‚úÖ A/B testing de diff√©rents mod√®les

---

## Recommandation Actuelle

Pour votre usage actuel, **Option 1 (Entra√Ænement Auto)** est parfait :

- ‚úÖ Premier lancement : 10s d'entra√Ænement (une seule fois)
- ‚úÖ Lancements suivants : Chargement instantan√©
- ‚úÖ Aucune config n√©cessaire
- ‚úÖ Le mod√®le est d√©j√† sauvegard√© gr√¢ce √† `asyncStorageHandler.ts`

### Ce qui a √©t√© am√©lior√©

Avant nos changements :
```
‚ùå Entra√Ænement √† CHAQUE lancement (50 epochs)
‚ùå Mod√®le jamais sauvegard√©
‚ùå ~15s de d√©lai √† chaque ouverture
```

Apr√®s nos changements :
```
‚úÖ Entra√Ænement UNIQUE au premier lancement (30 epochs)
‚úÖ Mod√®le sauvegard√© automatiquement
‚úÖ ~10s au premier lancement, <1s ensuite
‚úÖ Sauvegarde persistante via AsyncStorage
```

---

## Commandes Utiles

### V√©rifier si le mod√®le est sauvegard√©
```bash
# Dans React Native Debugger ou via adb
AsyncStorage.getItem('@ai_intent_metadata')
  .then(metadata => console.log(JSON.parse(metadata)))
```

### Supprimer le mod√®le sauvegard√© (forcer r√©-entra√Ænement)
```bash
AsyncStorage.removeItem('@ai_model_topology_intent_classifier')
AsyncStorage.removeItem('@ai_model_weights_intent_classifier')
AsyncStorage.removeItem('@ai_intent_metadata')
```

### Logs √† surveiller

**Premier lancement** (entra√Ænement) :
```
üß† Initializing Intent Classifier...
‚úì TensorFlow.js backend ready
üìö No model metadata found
üìö No existing model found. Training new model...
üèãÔ∏è Training model...
Epoch 0: loss = 2.88, accuracy = 0.09
Epoch 10: loss = 2.36, accuracy = 0.28
Epoch 20: loss = 1.65, accuracy = 0.57
Epoch 29: loss = 0.52, accuracy = 0.95
‚úÖ Training complete! Final accuracy: 95%
üíæ Model and weights saved successfully
‚úÖ Intent Classifier initialized successfully
```

**Lancements suivants** (chargement) :
```
üß† Initializing Intent Classifier...
‚úì TensorFlow.js backend ready
‚úÖ Model loaded from storage
‚úÖ Intent Classifier initialized successfully
```

---

## Troubleshooting

### Le mod√®le ne se charge pas

**Sympt√¥me** : Le mod√®le s'entra√Æne √† chaque lancement

**Solution** :
1. V√©rifiez les logs pour voir si `üíæ Model and weights saved successfully`
2. V√©rifiez AsyncStorage pour `@ai_model_topology_intent_classifier`
3. Assurez-vous que `asyncStorageHandler.ts` est import√© correctement

### Erreur "Cannot convert base64 to ArrayBuffer"

**Cause** : Probl√®me de compatibilit√© `btoa/atob` dans React Native

**Solution** : Installez un polyfill
```bash
npm install base-64
```

Puis dans `asyncStorageHandler.ts` :
```typescript
import { decode, encode } from 'base-64';

// Remplacer btoa/atob par encode/decode
```

### Le mod√®le est trop volumineux pour AsyncStorage

**Sympt√¥me** : Erreur "Quota exceeded"

**Solution** : AsyncStorage a une limite de ~6MB. Le mod√®le fait ~200KB, donc √ßa devrait passer. Si probl√®me :
- R√©duire le `vocabularySize` de 500 √† 300
- R√©duire les layers du mod√®le (128 ‚Üí 64, 64 ‚Üí 32)

---

## Conclusion

Le syst√®me actuel avec **sauvegarde automatique** est optimal pour votre app :

‚úÖ **Premier lancement** : ~10s d'entra√Ænement unique
‚úÖ **Tous les autres** : <1s de chargement
‚úÖ **Persistant** : Le mod√®le survit aux red√©marrages
‚úÖ **Automatique** : Aucune configuration requise

Si vous voulez aller plus loin avec un mod√®le pr√©-entra√Æn√©, suivez l'Option 2 ci-dessus !
